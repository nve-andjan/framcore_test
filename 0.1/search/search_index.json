{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>FRAM core package is the central package in FRAM that contains functionality for data transformation and definitions of interfaces. </p> <p>Power market models access data through FRAM core model - a model object that holds the data. Core model uses generic data structures and different abstraction levels to perform advanced data manipulations like aggregation, dissaggregation, handling time resolution, unit conversion etc.</p> <p>To install only core package, run <code>pip install fram-core</code>. But we recommend that you rather start by installing our simple demo.</p> <p></p>"},{"location":"#core-model","title":"Core model","text":"<p>The core model object is populated with the data from the database using Populator. Core model represents data as expressions and uses \"lazy\" approach, i.e. the calculations are not done immediately but are postponed until Expr.evaluate() is called. This approcah gives a much better performance when processing large data quantities. Data processing expressions are saved inside the components of the core model.  </p>"},{"location":"#core-model-components","title":"Core model components","text":"<p>Core model contains high-level and low-level components.</p>"},{"location":"#high-level-components","title":"High-level components","text":"<p>High-level components are \"recognizable\" components such as thermal power plants, consumers, transmission lines. They can be \"decomposed\" into low-level components.</p>"},{"location":"#low-level-components","title":"Low-level components","text":"<p>Low-level components are the most basic components that can be used to represent the high-level components - node and flow. They can describe anything in the power market model. For example, transmission is a node that has two flow arrows, while demand is a node that has only one \"incoming\" flow arrow.</p> <p>The advantage of decomposing high-level components into flow and node is that you can create generic algorithms with minimal code to manipulate the data and avoid duplicating code for similar operations. For example, you can write one generic function to find all hydropower plants or storage systems or to calculate yearly production, demand, export or import. </p>"},{"location":"#interfaces","title":"Interfaces","text":"<p>FRAM core package contains definition of interfaces necessary to run FRAM.</p> <ul> <li>Populator</li> </ul> <p>Abstract class that defines methods that must be implemented in a populator. FRAM data package contains our own implementation of populator that supports our database format. If you want to use your own database, you can write your own implementation of populator based on this interface.</p> <ul> <li>Solver</li> </ul> <p>Abstract class that defines methods that must be implemented in a model solver. FRAM JulES package contains our implementation of a solver for JulES power market model. Each market model is connected to FRAM using its own solver implementation. </p>"},{"location":"reference/","title":"Overview","text":"<p>Possible to add some general text here.</p>"},{"location":"reference/aggregators/","title":"Package <code>framcore.aggregators</code>","text":"<p>Some general text about aggregators.</p>"},{"location":"reference/aggregators/#framcore.aggregators.Aggregator.Aggregator","title":"Aggregator","text":"<p>               Bases: <code>Base</code>, <code>ABC</code></p> <p>Aggregator interface class.</p> <p>Public API is the aggregate and disaggregate methods.</p> <p>These methods come with the folloing calling rules: 1. Not allowed to call aggregate twice. Must call disaggregate before aggregate can be called again. 2. Disaggragate can only be called after aggregate has been called.</p> <p>Implementations should implement _aggregate and _disaggregate. - The general approach for aggregation is to group components, aggregated components in the same group, delete the detailed components, and add the mapping to self._aggregation_map. - The general approach for disaggregation is to restore the detailed components, move results from aggregated components to detailed components, and delete the aggregated components.</p>"},{"location":"reference/aggregators/#framcore.aggregators.Aggregator.Aggregator.aggregate","title":"aggregate","text":"<pre><code>aggregate(model: Model) -&gt; None\n</code></pre> <p>Aggregate model. Keep original data in case disaggregate is called.</p>"},{"location":"reference/aggregators/#framcore.aggregators.Aggregator.Aggregator.disaggregate","title":"disaggregate","text":"<pre><code>disaggregate(model: Model) -&gt; None\n</code></pre> <p>Disaggregate model back to pre-aggregate form. Move results into the disaggregated objects.</p>"},{"location":"reference/aggregators/#framcore.aggregators.Aggregator.Aggregator.get_aggregation_map","title":"get_aggregation_map","text":"<pre><code>get_aggregation_map() -&gt; dict[str, None | str | set[str]]\n</code></pre> <p>Return dictionary mapping from disaggregated to aggregated Component IDs.</p> <p>The mapping should tell you which of the original Components were aggregated into which new Components. Components which are left as is should not be in the mapping. Components which are deleted without being aggregated are mapped to None.</p>"},{"location":"reference/aggregators/#framcore.aggregators.HydroAggregator.HydroAggregator","title":"HydroAggregator","text":"<p>               Bases: <code>Aggregator</code></p> <p>Aggregate hydro modules into two equivalent modules based on the regulation factor, into one regulated and one unregulated module per area.</p> <p>Aggregation steps (self._aggregate): 1. Group modules based on their power nodes (self._group_modules_by_power_node)     - Modules with generators are grouped based on their power nodes.     - Reservoirs are assigned to the power node which has the highest cumulative energy equivalent downstream of the reservoir. This is because JulES     currently only support one-to-one mapping of detailed and aggregated reservoirs.     - Reservoirs without generators downstream are ignored in the aggregation.     - TODO: Add possibility to only aggregate HydroModules in certain areas, so that different areas can have different aggregation levels. 2. Group area modules into regulated and unregulated based on regulation factor (self._group_modules_by_regulation_factor)     - Regulation factor = upstream reservoir capacity / yearly upstream inflow. Modules with generators that have regulation factor &lt;= self._ror_threshold     are grouped into unregulated run-of-river modules, the other modules with generators are grouped into regulated reservoir modules.     - All reservoirs are assigned to the regulated group.     - Generators without upstream inflows are ignored in the aggregation. 3. Make aggregated hydro module for each group (self._aggregate_groups)     - The resulting HydroModule has a generator with energy equivalent of 1 kWh/m3. The inflow, discharge capacity and reservoir capacity     is calculated based on energy and transformed back to water using this energy equivalent.     - Generation capacity (release_capenergy_equivalent/agg_energy_equivalent, capacity of hydraulic couplings not double counted)     - Energy reservoir capacity (res_capenergy_equivalent_downstream/agg_energy_equivalent)     - Gross energy inflow (inflow_upenergy_equivalent/agg_energy_equivalent) - TODO: Add possibility to adjust inflow to closer represent net inflow     - Inflow profiles weighted based on gross energy inflow (inflow_up_per_profileenergy_equivalent) - calc from core model using self._map_topology()     - TODO: Other details like pumps and environmental constraints are currently ignored in the aggregation. 3a. Aggregate results if all modules in group have results.     - Production is the sum of production levels with weighted profiles     - Reservoir filling is the sum of energy reservoir filling levels (filling*energy_equivalent_downstream/agg_energy_equivalent) with weighted profiles     - TODO: Spill, bypass and pumping results are currently ignored in the aggregation.     - TODO: Add possibility to skip results aggregation. 3b. Make new hydro module and delete original modules from model data. 4. Add mapping from detailed to aggregated modules to self._aggregation_map.</p> <p>Disaggregation steps (self._disaggregate): 1. Restore original modules from self._original_data. 2. Move production and filling results from aggregated modules to detailed modules, weighted based on production capacity and reservoir capacity.     - TODO: Spill and bypass results are currently ignored in the disaggregation. 3. Delete aggregated modules.</p> Comments <ul> <li>It is recommended to only use the same aggregator type once on the same components of a model. If you want to go from one aggregation level to another, it is better to use model.disaggregate first and then aggregate again. This is to keep the logic simple and avoid complex expressions. We have also logic that recognises if result expressions come from aggregations or disaggregations. When aggregating or disaggregating these, we can go back to the original results rather than setting up complex expressions that for examples aggregates the disaggregated results.</li> <li>Levels and profiles are aggregated separately, and then combined into attributes.</li> <li>We have chosen to eagerly evaluate weights for aggregation and disaggregation of levels and profiles. This is a balance between eagerly evaluating everything, and setting up complex expressions. Eagerly evaluating everything would require setting up new timevectors after eager evaluation, which is not ideal. While setting up complex expressions gives expressions that are harder to work with and slower to query from.</li> </ul> <p>Attributes:</p> Name Type Description <code>_metakey_energy_eq_downstream</code> <code>str</code> <p>Metadata key for energy equivalent downstream.</p> <code>_data_dim</code> <code>SinglePeriodTimeIndex</code> <p>Data dimension for eager evalutation.</p> <code>_scen_dim</code> <code>FixedFrequencyTimeIndex</code> <p>Scenario dimension for eager evalutation.</p> <code>_grouped_modules</code> <code>dict[str, set[str]]</code> <p>Mapping of aggregated modules to detailed modules. agg to detailed</p> <code>_grouped_reservoirs</code> <code>dict[str, set[str]]</code> <p>Mapping of aggregated reservoirs to detailed reservoirs. agg to detailed</p> <code>_ror_threshold</code> <code>float</code> <p>Regulation factor (upstream reservoir capacity / yearly upstream inflow) threshold for run-of-river classification. Default is 0.5.</p> <p>Parent Attributes (see framcore.aggregators.Aggregator):     _is_last_call_aggregate (bool | None): Tracks whether the last operation was an aggregation.     _original_data (dict[str, Component | TimeVector | Curve | Expr] | None): Original detailed data before aggregation.     _aggregation_map (dict[str, set[str]] | None): Maps aggregated components to their detailed components. detailed to agg</p>"},{"location":"reference/aggregators/#framcore.aggregators.NodeAggregator.NodeAggregator","title":"NodeAggregator","text":"<p>               Bases: <code>Aggregator</code></p> <p>Aggregate groups of nodes for a commodity. Subclass of Aggregator.</p>"}]}